\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Logistic sigmoid function\relax }}{11}{figure.caption.5}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Loss function for $y=0$ and $y=1$\relax }}{17}{figure.caption.6}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces Regularisation constant effect on underfitting and overfitting in a model}}{28}{figure.caption.7}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces Decision boundary for two inputs $\bm {x}_1$ and $\bm {x}_2$\relax }}{29}{figure.caption.8}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Network diagram for one hidden layer neural network\relax }}{42}{figure.caption.10}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Gradient of logistic sigmoid function\relax }}{45}{figure.caption.11}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces $\qopname \relax o{tanh}$ function\relax }}{46}{figure.caption.12}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Gradient of $\qopname \relax o{tanh}$ function\relax }}{47}{figure.caption.13}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces ReLU function\relax }}{49}{figure.caption.14}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Gradient of ReLU\relax }}{50}{figure.caption.15}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces ReLU and some of its common variations\relax }}{51}{figure.caption.16}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Swish function\relax }}{53}{figure.caption.17}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Gradient of swish function\relax }}{54}{figure.caption.18}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Forward and backward propagation in a neural network layer\relax }}{56}{figure.caption.19}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Two-dimensional cross-correlation operation}}{61}{figure.caption.20}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Representation of sparse and full connectivity}}{61}{figure.caption.21}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Vertical edge detection\relax }}{62}{figure.caption.22}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Two-dimensional cross-correlation with padding}}{64}{figure.caption.23}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Cross-correlation with strides of $3$ and $2$ for height and width respectively}}{65}{figure.caption.24}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Cross-correlation computation with $2$ input channels}}{66}{figure.caption.25}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Maximum pooling with a pooling window shape of $2 \times 2$}}{67}{figure.caption.26}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Fully connected layer before and after dropout}}{69}{figure.caption.27}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The PlantVillage image dataset. This dataset contains 38 categories of diseased or healthy leaf images\relax }}{75}{figure.caption.28}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Bar chart showing the number of images in each class\relax }}{76}{figure.caption.29}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Simplified base model architecture\relax }}{77}{figure.caption.30}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces VGG16 model architecture}}{80}{figure.caption.32}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Residual learning blocks}}{81}{figure.caption.33}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces A block of ResNeXt with cardinality = 32}}{82}{figure.caption.34}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Training loss for different models}}{85}{figure.caption.37}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Confusion matrix for different models}}{86}{figure.caption.38}%
\addvspace {10\p@ }
